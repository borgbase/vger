---
name: s3
description: "Validate vger S3 backend with bandwidth-aware corpus backup and restore"
---

# S3 Backend â€” Corpus Backup & Restore

## Goal

Validate vger backup and restore correctness on the S3 backend using the smaller remote corpus.

## Scope

- **Backend**: `s3` (credentials and endpoint from `~/vger.sample.yaml`)
- **Source dataset**: `~/corpus-remote`
- **Verification**: restored tree matches source tree exactly

## Prerequisites

1. Create config from `~/vger.sample.yaml` with S3 repo definition
2. `export VGER_PASSPHRASE=123`
3. Ensure `rclone` is configured for S3 cleanup (use credentials from sample config)

## Remote Cleanup (before each run)

Delete S3 repo contents between runs:
```bash
rclone delete <s3_remote:path> --rmdirs
```
- Do NOT use `rclone purge` (may fail with 403 on restricted buckets)
- If bucket root delete is denied, stick with content-only deletion

## Test Procedure

1. Initialize repo:
   ```bash
   vger init -c <config> -R s3
   ```
2. Run backup:
   ```bash
   vger backup -c <config> -R s3 -l remote-corpus ~/corpus-remote
   ```
3. Confirm snapshot:
   ```bash
   vger list -c <config> -R s3 --last 3
   ```
4. Capture latest snapshot ID.
5. Restore to empty temp directory:
   ```bash
   vger extract -c <config> -R s3 --dest <restore_dir> <snapshot_id>
   ```
6. Integrity check:
   ```bash
   vger check -c <config> -R s3
   ```

## Validation

1. Snapshot exists for label `remote-corpus`
2. Restore completes successfully
3. `diff -qr ~/corpus-remote <restore_dir>` reports no differences
4. Optional: SHA256 manifest comparison

## Failure Cases to Record

- S3 auth or endpoint errors
- Partial upload or timeout during backup
- Restore mismatch vs source
- `vger check` failures

## Cleanup

1. Remove restore temp directory
2. Clean S3 path with `rclone delete --rmdirs` unless keeping for debugging
